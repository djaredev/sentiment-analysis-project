üê¨ Delfin project
# Implementaci√≥n y an√°lisis de desempe√±o de t√©cnicas de aprendizaje autom√°tico para el an√°lisis de sentimientos

## üìù Requisitos:
- Dataset [sentiment140](https://www.kaggle.com/datasets/kazanova/sentiment140)
- Vector de representacion de palabras [glove](https://nlp.stanford.edu/projects/glove/)

## ü§ñ Tecnicas analisadas:
- Large Language Model (LLM)
- Support Vertor Machine (SVM)
- Long Short-Term Memory (LSTM)

## üìÑ Resumen:

Los datos usados para realizar las pruebas fue el dataset sentiment140 una base de datos  muy utilizada en an√°lisis de sentimientos, el dataset contiene 1,600,000 tweets extra√≠dos directo de la API de Twitter que est√°n etiquetados con dos clases diferentes (0 = negativo, 4 = positivo). 
A los  datos se les aplic√≥ t√©cnicas de preprocesamiento de datos para limpiarlos, estandarizarlos y adecuarlos para el uso en los modelos a excepci√≥n de el LLM ya que este cuenta con su propia capa que hace este proceso.

Algo a destacar del preprocesamiento realizado es que se us√≥ incrustaci√≥n de palabras (Word embeddings) para representar las palabras en forma de vectores, una t√©cnica muy efectiva a la hora de vectorizar las palabras ya que los embeddings capturan relaciones sem√°nticas y sint√°cticas adem√°s tiene una representaci√≥n densa y de baja dimensi√≥n.

## üìä Resultados:
Para evaluar los modelos se usaron las m√©tricas que se basan en la matriz de confusi√≥n que se genera a partir de los datos que predijo el modelo y los datos reales, tanto BERT como el modelo LSTM fueron entrenados durante 8 epochs.

**Accuracy (Exactitud):** Esta m√©trica mide que tambi√©n es la predicci√≥n en comparaci√≥n con los datos reales.
En esta m√©trica el mejor modelo fue BERT con una accuracy de 84% durante el entrenamiento y 83% con los datos de prueba, seguido por la red LSTM con una accuracy 84% durante el entrenamiento y 82% con los datos de prueba, por √∫ltimo la SVM con una accuracy con los datos de prueba de 75%.

**Precisi√≥n:** Esta m√©trica mide de todas las instancias que el modelo predice para una clase especifica, cu√°ntas  son realmente de esa clase.
En esta m√©trica el mejor modelo fue BERT con una precisi√≥n de 83% en la clase negativa y 84% en la clase positiva, seguido por el modelo LSTM con una precisi√≥n de 82% en la clase negativa y 83% en la clase positiva, por √∫ltimo la SVM con una precisi√≥n de 75% y 76% respectivamente.

**Recall (Sensitivity):** Esta m√©trica mide la capacidad del modelo para predecir una clase espec√≠fica correctamente.
En esta m√©trica tanto BERT como LSTM tuvieron un recall de 84% en la clase negativa pero un 82% y 81% en la clase positiva respectivamente, por √∫ltimo la SVM con una precisi√≥n de 76% en la clase negativa y 75% en la positiva.

**F1-Score:** Es una m√©trica que combina la precisi√≥n y el recall en un solo valor proporcionando una medida equilibrada del rendimiento del modelo.
En esta m√©trica tanto BERT como LSTM tuvieron un f1-score de 83% en la clase negativa pero un 83% y 82% en la clase positiva respectivamente, por √∫ltimo la SVM con una precisi√≥n de 76% en la clase negativa y 75% en la positiva.

### ‚úÖ Conclusiones:

En general los modelos BERT y LSTM tiene un rendimiento muy similar en todas las m√©tricas en las que se les evalu√≥, pero con grandes diferencias en cuanto al consumo computacional y al tama√±o siendo el modelo LSTM el de mayor tama√±o con un total de 40,686,000 par√°metros con un consumo en memoria de 155.20 MB mientras que el modelo BERT tuvo un tama√±o total de 4,386,178 par√°metros con un consumo en memoria de 16.73 MB teniendo en cuenta que BERT cuenta con diferentes tama√±os de par√°metros, siendo al que se le realiz√≥ fine tuning en esta investigaci√≥n el m√°s peque√±o de todos, por lo que con un modelo similar de tama√±o al modelo LSTM usado se podr√≠a tener un mejor rendimiento. 
Por otro lado, SVM rinde peor, est√° por debajo en todas las m√©tricas en comparaci√≥n con los otros 2 modelos, tambi√©n, es el que menos tiempo de ejecuci√≥n necesito, adem√°s de que tiene menos consumo computacional en comparaci√≥n con los otros modelos.


En conclusi√≥n hacer fine tuning a un LLMs result√≥ mejor y m√°s f√°cil que que crear una red LSTM customizada, preprocesar los datos y manejar incrustaciones de palabras, etc, por otro lado t√©cnicas como SVM son m√°s simples y m√°s r√°pidas pero con un rendimiento inferior.


Los LLMs son una gran alternativa a las t√©cnicas m√°s conocidas, para afrontar problemas de an√°lisis de sentimientos, ya que estos modelos han sido entrenados con grandes cantidades de texto y estos pueden ser ajustados a muchas tareas relacionadas con el NLP.




